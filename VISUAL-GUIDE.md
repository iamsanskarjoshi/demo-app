# ğŸ¯ Load Balancing Setup - Visual Guide

## Before vs After

### âŒ BEFORE (Original Setup)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      MACHINE 1          â”‚
â”‚                         â”‚
â”‚  User API :3001         â”‚
â”‚  Product API :3002      â”‚
â”‚  Email Worker           â”‚
â”‚  UI :80                 â”‚
â”‚                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”‚ Single connection
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      MACHINE 2          â”‚
â”‚                         â”‚
â”‚  Order API :3003        â”‚
â”‚  PostgreSQL :5432       â”‚
â”‚  Redis :6379            â”‚
â”‚  Data Sync Worker       â”‚
â”‚                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Problems:
âŒ No redundancy
âŒ No load distribution  
âŒ Single point of failure
âŒ M1 goes down = User/Product APIs unavailable
âŒ M2 goes down = Order API + Database unavailable
```

### âœ… AFTER (With Load Balancing)
```
         Client Requests
              â”‚
              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Can hit either    â”‚
    â”‚   load balancer!    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚           â”‚
         â†“           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MACHINE 1   â”‚ â”‚  MACHINE 2   â”‚
â”‚              â”‚ â”‚              â”‚
â”‚  Nginx :8080 â”œâ”€â”¤  Nginx :8080 â”‚
â”‚  (LB)        â”‚ â”‚  (LB)        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                 â”‚
       â†“                 â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ User    â”‚â—„â”€â”€â”€â”€â”€â–ºâ”‚ User    â”‚
  â”‚ :3001   â”‚       â”‚ :3011   â”‚
  â”‚(Primary)â”‚       â”‚(Replica)â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Product â”‚â—„â”€â”€â”€â”€â”€â–ºâ”‚ Product â”‚
  â”‚ :3002   â”‚       â”‚ :3012   â”‚
  â”‚(Primary)â”‚       â”‚(Replica)â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Order   â”‚â—„â”€â”€â”€â”€â”€â–ºâ”‚ Order   â”‚
  â”‚ :3013   â”‚       â”‚ :3003   â”‚
  â”‚(Replica)â”‚       â”‚(Primary)â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Benefits:
âœ… High Availability
âœ… Load Distribution
âœ… Automatic Failover
âœ… Any machine can serve requests
âœ… Services continue if one machine fails
```

## Request Flow Example

### Scenario: User creates an order

```
1. Client Request
   â”‚
   â””â”€â”€â–º http://MACHINE1_IP:8080/api/orders
        (Or http://MACHINE2_IP:8080/api/orders)
        â”‚
        â†“
2. Nginx Load Balancer (on either machine)
   â”‚
   â”œâ”€â”€â–º Checks: Which backend has fewer connections?
   â”‚     - Machine 1 Order Service :3013 (2 connections)
   â”‚     - Machine 2 Order Service :3003 (1 connection)
   â”‚
   â””â”€â”€â–º Routes to: Machine 2 :3003 âœ“
        â”‚
        â†“
3. Order Service on Machine 2
   â”‚
   â”œâ”€â”€â–º Saves order to PostgreSQL
   â”‚     â””â”€â”€â–º Success âœ“
   â”‚
   â””â”€â”€â–º Pushes notification to Redis queue
        â””â”€â”€â–º Success âœ“
        â”‚
        â†“
4. Response back to client
   â”‚
   â””â”€â”€â–º HTTP 201 Created
        {"id": 123, "status": "pending", ...}

5. Email Worker (Machine 1)
   â”‚
   â””â”€â”€â–º Picks up notification from Redis
        â””â”€â”€â–º Sends email âœ“
```

## Failover Example

### Scenario: Machine 1's User Service crashes

```
BEFORE CRASH:
Client â†’ Nginx (M1) â†’ User Service (M1) âœ“
Client â†’ Nginx (M2) â†’ User Service (M1) âœ“

AFTER M1 User Service CRASHES:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Nginx detects failure             â”‚
â”‚  (max_fails=3, fail_timeout=10s)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
Client â†’ Nginx (M1) â†’ User Service (M2) âœ“
                      (Automatic!)
         â”‚
         â†“
Client â†’ Nginx (M2) â†’ User Service (M2) âœ“
                      (Already using it)

Result: ZERO DOWNTIME! ğŸ‰
```

## Port Map - Complete View

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        MACHINE 1                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Service             â”‚ Port â”‚ Type      â”‚ Accessible From     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ User Service        â”‚ 3001 â”‚ Primary   â”‚ Both machines       â”‚
â”‚ Product Service     â”‚ 3002 â”‚ Primary   â”‚ Both machines       â”‚
â”‚ Order Service       â”‚ 3013 â”‚ Replica   â”‚ Both machines       â”‚
â”‚ Nginx Load Balancer â”‚ 8080 â”‚ LB        â”‚ External + Internal â”‚
â”‚ UI Service          â”‚  80  â”‚ Frontend  â”‚ External            â”‚
â”‚ Email Worker        â”‚  -   â”‚ Worker    â”‚ N/A                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        MACHINE 2                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Service             â”‚ Port â”‚ Type      â”‚ Accessible From     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ User Service        â”‚ 3011 â”‚ Replica   â”‚ Both machines       â”‚
â”‚ Product Service     â”‚ 3012 â”‚ Replica   â”‚ Both machines       â”‚
â”‚ Order Service       â”‚ 3003 â”‚ Primary   â”‚ Both machines       â”‚
â”‚ Nginx Load Balancer â”‚ 8080 â”‚ LB        â”‚ External + Internal â”‚
â”‚ PostgreSQL          â”‚ 5432 â”‚ Database  â”‚ Both machines       â”‚
â”‚ Redis               â”‚ 6379 â”‚ Queue     â”‚ Both machines       â”‚
â”‚ Data Sync Worker    â”‚  -   â”‚ Worker    â”‚ N/A                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Access Patterns

### âŒ OLD WAY (Direct Access)
```bash
# Had to know which machine has which service
curl http://machine1:3001/api/users     # User on M1 only
curl http://machine1:3002/api/products  # Product on M1 only  
curl http://machine2:3003/api/orders    # Order on M2 only

# Problem: Services locked to specific machines
```

### âœ… NEW WAY (Through Load Balancer)
```bash
# Access ANY service through ANY machine!
curl http://machine1:8080/api/users     # Works!
curl http://machine1:8080/api/products  # Works!
curl http://machine1:8080/api/orders    # Works!

curl http://machine2:8080/api/users     # Also works!
curl http://machine2:8080/api/products  # Also works!
curl http://machine2:8080/api/orders    # Also works!

# Benefit: True high availability!
```

## Load Distribution Example

```
10 Requests to User Service:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Request 1  â†’  Nginx  â†’  Machine 1 (fewer connections)
Request 2  â†’  Nginx  â†’  Machine 2 (fewer connections)
Request 3  â†’  Nginx  â†’  Machine 1 (fewer connections)
Request 4  â†’  Nginx  â†’  Machine 2 (fewer connections)
Request 5  â†’  Nginx  â†’  Machine 1 (fewer connections)
Request 6  â†’  Nginx  â†’  Machine 2 (fewer connections)
Request 7  â†’  Nginx  â†’  Machine 1 (fewer connections)
Request 8  â†’  Nginx  â†’  Machine 2 (fewer connections)
Request 9  â†’  Nginx  â†’  Machine 1 (fewer connections)
Request 10 â†’  Nginx  â†’  Machine 2 (fewer connections)

Result: 50/50 distribution! âš–ï¸
(Algorithm: least_conn ensures balanced load)
```

## Health Check Flow

```
Every 10 seconds, Nginx checks each backend:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Health Check Cycle                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
Check Machine 1 User Service :3001
  â””â”€â”€â–º Success? âœ“ â†’ Keep in rotation
       Failure? âœ— â†’ Mark as down, retry in 10s

Check Machine 2 User Service :3011
  â””â”€â”€â–º Success? âœ“ â†’ Keep in rotation
       Failure? âœ— â†’ Mark as down, retry in 10s

(Repeat for all services...)

If backend fails 3 times consecutively:
  â†’ Remove from rotation
  â†’ Route traffic to healthy backend
  â†’ Retry every 10 seconds
  â†’ Add back when healthy
```

## Configuration Snippet Explained

```nginx
upstream user_service_backend {
    least_conn;           # Algorithm: route to least busy
    
    server 172.31.11.13:3001    # Machine 2's User Service
           max_fails=3          # Fail after 3 attempts
           fail_timeout=10s;    # Retry after 10 seconds
    
    server 127.0.0.1:3011       # Local User Service
           max_fails=3
           fail_timeout=10s;
}
```

## Deployment Checklist

```
MACHINE 2 (Deploy First):
â”œâ”€ [ ] Update nginx/nginx.conf with Machine 1 IP
â”œâ”€ [ ] Open firewall ports (3003, 3011, 3012, 8080, 5432, 6379)
â”œâ”€ [ ] Run: ./deploy-with-lb.sh
â”œâ”€ [ ] Verify: curl http://localhost:8080/health
â””â”€ [ ] Check: docker-compose ps (all should be Up)

MACHINE 1 (Deploy Second):
â”œâ”€ [ ] Update .env with MACHINE2_IP
â”œâ”€ [ ] Update nginx/nginx.conf with Machine 2 IP
â”œâ”€ [ ] Open firewall ports (3001, 3002, 3013, 8080, 80)
â”œâ”€ [ ] Run: ./deploy-with-lb.sh
â”œâ”€ [ ] Verify: curl http://localhost:8080/health
â””â”€ [ ] Check: docker-compose ps (all should be Up)

TESTING:
â”œâ”€ [ ] Run: ./test-load-balancing.sh
â”œâ”€ [ ] Create data through both load balancers
â”œâ”€ [ ] Stop a service, verify failover works
â”œâ”€ [ ] Check nginx status: curl localhost:8080/nginx-status
â””â”€ [ ] Monitor logs: docker logs nginx-lb -f
```

## Troubleshooting Visual Guide

```
Problem: Nginx returns 502 Bad Gateway
         â”‚
         â†“
    Check backend services
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚         â”‚
    â†“         â†“
  Running?  Healthy?
    â”‚         â”‚
   No        No
    â”‚         â”‚
    â†“         â†“
  Start    Check logs
  Service  Fix issue
    â”‚         â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚
         â†“
   Restart Nginx
         â”‚
         â†“
      Test again


Problem: Requests only go to one machine
         â”‚
         â†“
    Check Nginx upstream config
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚         â”‚
    â†“         â†“
  Correct   Firewall
   IPs?      open?
    â”‚         â”‚
   No        No
    â”‚         â”‚
    â†“         â†“
  Update    Open ports
  Config    sudo ufw
    â”‚         â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚
         â†“
   Restart Nginx
         â”‚
         â†“
   Test connectivity
```

## Success Indicators

```
âœ… All services show "Up" in docker-compose ps
âœ… curl http://localhost:8080/health returns 200
âœ… curl http://localhost:8080/nginx-status shows stats
âœ… Can create/read data through both load balancers
âœ… Data is consistent regardless of which LB used
âœ… Stopping a service doesn't break API calls
âœ… Nginx logs show distribution to both machines
âœ… test-load-balancing.sh passes all tests
```

## Quick Commands Reference

```bash
# Check everything is running
docker-compose ps

# View load balancer logs
docker logs nginx-lb -f

# Test health
curl http://localhost:8080/health

# Check Nginx status
curl http://localhost:8080/nginx-status

# Test API through LB
curl http://localhost:8080/api/users

# Create data through LB
curl -X POST http://localhost:8080/api/users \
  -H "Content-Type: application/json" \
  -d '{"name":"Test","email":"test@example.com","age":25}'

# Simulate failure (test failover)
docker stop user-service
curl http://localhost:8080/api/users  # Still works!
docker start user-service

# Full load balancing test
./test-load-balancing.sh
```

---

**Your setup now matches exactly what your senior requested!** ğŸ‰

Every machine runs Nginx, services are replicated, and load is distributed automatically with failover support!
